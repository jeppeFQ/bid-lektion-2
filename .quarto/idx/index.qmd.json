{"title":"(D)en digital verden – utopi eller dystopi?","markdown":{"yaml":{"title":"(D)en digital verden – utopi eller dystopi?","subtitle":"","author":"Jeppe Fjeldgaard Qvist","date":"today","format":{"revealjs":{"include-after-body":"resources/timer.html","navigation-mode":"linear","slide-number":"c","show-slide-number":"print","embed-resources":true,"self-contained-math":true,"smaller":true,"scrollable":true,"theme":"default","include-in-header":[{"text":"<link href=\"https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap\" rel=\"stylesheet\">\n<style>\n.reveal {\n  font-family: \"Libre Baskerville\", serif !important;\n}\n.reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {\n  font-family: \"Libre Baskerville\", serif !important;\n}\n</style>\n"}]}}},"headingText":"Dagens program","headingAttr":{"id":"","classes":[],"keyvalue":[["background-image","resources/samfund.png"],["background-size","50%"],["background-position","center"],["background-repeat","no-repeat"],["background-opacity","0.5"]]},"containsRefs":false,"markdown":"\n\n\n- dd   \n- ccc   \n\n---\n\n![](resources/turk.jpg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- [LaMDA](https://arstechnica.com/tech-policy/2022/07/google-fires-engineer-who-claimed-lamda-chatbot-is-a-sentient-person/) og maskiner med bevidsthed?\n:::\n\n## Det digitale samfund {background-image=\"resources/samfund.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n> Det, at flere og flere aspekter af vores liv og hverdag digitaliseres, stiller ikke kun store krav til de underliggende systemer, men rejser også mange fundamentale spørgsmål; såvel tekniske som etiske.\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Hvem bærer skylden: Maskinen eller Rafaela, der var \"andenpilot\"?\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Al data, der ligger til grund for maskines klassificerings-evner bygger på data som mennesker har haft ansvaret for. Maskiner forholder sig ikke til andet end tal. \n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Derfor kan maskiner ikke være sexistiske eller racistiske. Men der eksisterer (stadig) systematisk sexisme og racisme og disse forhold vil være afspejlet i den data vi træner modeller på. \n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n:::{.incremental}\n* *Datatype og -omfang*: Ægte data eller ideel data (the unicorn)? \n* *Definerede opgaver*: Maskiner besejrer os, fordi vi beder dem om det. Det er ikke en skjult *motivation* (Luda, Tay: \"thinking about you\"). \n* *Tabsfunktionen*: målet vi bruger til at bestemme, hvor langt maskinen er fra at løse problemet. En grundlæggende menneskebestemt komponent. \n:::\n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n> *\"Du har en befolkning, hvor 0,5 procent får en alvorlig sygdom, og træner en model til at identificere dem. Modellen opnår hurtigt en høj træfsikkerhed på 99,5 procent, men er ikke i stand til at identificere en eneste af de syge. Hvad er der sket?\"* (fra Inga Strümke)\n\n<span class=\"timer\" data-time=\"120\"></span>\n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n:::{.incremental}\n* Udviklere bestemmer hvornår en model er færdig. \n    * alt fra simpel ML og *deep learning* handler grundlæggende \"bare\" om kontinuerlig tilpasning af parametre indtil fejlen er så lille som muligt. \n    * **Universel approximation**: tilnærmelse af den sande funktion og fordeling.  \n    * Det meste af fremgangen indenfor AI er takket være **brute force** og *enorme mængde data*, snarer end vi har formået at putte mere \"intellegens\" ind i modeller. \n:::\n\n## Skyggesiderne af det digital samfund {background-image=\"resources/bad-ai.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.2\"}\n\n<br>\n\n**De klassiske:**\n\n- Datasikkerhed\n- Privatliv \n- Rettigheder (og ejerskab)\n\n**De \"nye\":**\n\n- Diskrimination og gennemsigtighed\n- (Klima)\n- (Ubegrundet/overdreven optimisme?)\n\n## (Data)sikkerhed {background-image=\"resources/eu.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n:::{.incremental}\n* **GDPR**: for lidt og for meget?\n    * Forskningsarbejde, der ikke må anvendes i praksis. \n    * Production af personfølsom data ([2018 studie på Facebook data](https://doi.org/10.1073/pnas.1802331115))\n    * Antag at de store techvirksomheder ved *midst* lige så meget om dig, som du selv gør!\n    * Giver mere regulering mening, når vi ikke ved hvad der bliver muligt i morgen?\n::: \n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Privatliv (1) {background-image=\"resources/privat.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n:::{.incremental}\n- Stort set alt hvad vi gør med digitale værktøjer (*computer, telefon, tv, SoMe, kort, kreditkort, ...*) **generer data**. \n  - I praksis er denne data ikke længere anonym. Når der er nok data, er det \"nemt\" at identificere personer. \n  - **The privacy paradox**. \n  - Det meste data er ikke *for* os, det er *om* os. \n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Privatliv (2) \n\n![](resources/peppespizza.jpeg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- **Anonymous Video Analytics**: Køn, Aldersgruppe, Attention time, Smile.\n- Tesla's overvågning af gadebilledet. Hvorfor er det mere acceptabelt? \n:::\n\n## Privatliv (3)\n\n:::{.incremental}\n- **Federated learning**: Google opfandt en måde at trænie modeller på vores mobiler, uden hjemsendelse af persondata; kun parametre. \n- **Formålsglidning**: bedste eksempel er NSA \n- Techgiganterne der ved meget om os er primært Amerikanske; resten er primært Kinesiske.\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Rettigheder og ejerskab {background-image=\"resources/antiai.png\" background-size=\"100%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.3\"}\n\n:::{.incremental}\n- Hvad ejer vi egentlig, når vi først har lagt det på nettet?\n- OpenAI 4. november 2022: *you own the generations you create with DALL-E* ([pkt. 5](https://help.openai.com/en/articles/6704941-dall-e-api-faq))\n  - **AI *er* kreative i en snæver defination af begrebet**. Men modeller er trænet på \"dit\" arbejde. \n- Vi kan ikke lave plagiat kontrol på en AI model, men ...    \n  - **Bør vi vandmærke AI modeller?**   \n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Rettigheder {background-image=\"resources/crime.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n**Correctional Offender Management Profiling for Alternative Sanctions** ([COMPAS](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing))\n\n> *It assesses not just risk but also nearly two dozen so-called “criminogenic needs” that relate to the major theories of criminality, including “criminal personality,” “social isolation,” “substance abuse” and “residence/stability.” Defendants are ranked low, medium or high risk in each category.*\n\n:::{.incremental}\n::: {style=\"font-size: 0.9em;\"}\n- AI modeller er (typisk) udvikling af folk, der ikke er eksperter i **substansfeltet**. De er eksperter i AI og ML. \n- Neurale netværk er for kompliceret til at vi i dag, som mennesker kan se, hvad det er maskinen \"ser\". \n  - **Subsymbolsk viden**: Dataen mister sin betydning for mennesker.\n    - **Grænsetilfælde**: Det lange hale problem.  \n    - En ting er at et system virker, men hvis vi ikke ved *hvorfor* det virker, bør vi så tage det i brug .\n:::\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Diskrimination og gennemsigtighed (1)\n\n![](resources/pic-discrimination.jpg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- Det er mennesker, der har adgang til hvilke kategorier en model har adgang til. (Sandsynligvis har afro- og/eller amerikaner, ikke været tilgængelig).\n:::\n\n## Diskrimination og gennemsigtighed (2) {background-image=\"resources/dis.png\" background-size=\"70%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.15\"}\n\n[Amazon Scraps Secret AI Recruiting Engine that Showed Biases Against Women](https://www.ml.cmu.edu/news/news-archive/2016-2020/2018/october/amazon-scraps-secret-artificial-intelligence-recruiting-engine-that-showed-biases-against-women.html)\n\n:::{.incremental}\n  - Endte som en *mande-detector*: Vi henter data fra en verden hvor hvide mænd har haft en priviligeret position. \n  - Er modellen sexistisk, hvis den kun har \"kendt\" en (data)verden, hvor strukturel sexisme eksisterer?\n  - Data kan ikke have bias. Data *er* bare. \n  - **Gennemsigtighed eller regulering?**\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Diskrimination og gennemsigtighed (3) {background-image=\"resources/kant.jpg\" background-size=\"100%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.3\"}\n\n*Scrolling, autonomi og selvforstærkende mekanismer.*\n\n:::{.incremental}\n- Danner vi ønsker, eller bliver vi nudget til bestemte ønsker? \n- **Anbefalingssystemer**: er det tilpasning eller manipulation?\n- Deep fakes (billede og lyd). Google vi ikke frigive **AudioLM**.\n    * Lyd og billede kan ikke skelnes fra originaler. \n::: \n\n## Hvad er vi villige til at acceptere i et digitalt samfund? \n\n:::{.incremental}\n\n1. Har vi tænkt over hvad vi vil og ikke vil være med til?\n\n2. Opvejet fordele og ulemper ...\n    * Kan vi overhovedet tage stilling til disse spørgsmål på forhånd eller er vi nødt til at diskutere det løbende?\n\n3. Hvem beslutter hvad vi vil og ikke vil? Og hvad er deres motivation for at beslutte som de gør?\n    * ...Befolkningens ve og vel?   \n    * ...Personlig fortjeneste?    \n    * ...Magt?    \n\n4. Hvad er alternativet?\n    * Kan vi sige fra, hvad ville der ske og hvordan gør vi?    \n\n:::\n\nDet vi kan sige er, at vi altid vil være på bagkant af teknologien. Vi skal derfor kunne forholde os kritisk til teknologi med kort varsel-\n\nI den ideelle verden:\n\n:::{.incremental}\n\n1. ... er der gennemsigtighed omkring beslutningsprocesser og aktørers roller\n2. ... er der plads til demokratisk proces\n3. ... er det bl.a. jer og jeres fagfæller, mere end nogen anden der skal være med til at finde svarene ...\n\n:::\n\n# Grupperdannelse og præsentation af mini-projekter","srcMarkdownNoYaml":"\n\n## Dagens program {background-image=\"resources/samfund.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.5\"}\n\n- dd   \n- ccc   \n\n---\n\n![](resources/turk.jpg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- [LaMDA](https://arstechnica.com/tech-policy/2022/07/google-fires-engineer-who-claimed-lamda-chatbot-is-a-sentient-person/) og maskiner med bevidsthed?\n:::\n\n## Det digitale samfund {background-image=\"resources/samfund.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n> Det, at flere og flere aspekter af vores liv og hverdag digitaliseres, stiller ikke kun store krav til de underliggende systemer, men rejser også mange fundamentale spørgsmål; såvel tekniske som etiske.\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Hvem bærer skylden: Maskinen eller Rafaela, der var \"andenpilot\"?\n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Al data, der ligger til grund for maskines klassificerings-evner bygger på data som mennesker har haft ansvaret for. Maskiner forholder sig ikke til andet end tal. \n\n---\n\n![](resources/pic-accident.jpg){fig-align=\"center\" width=50%}\n\nEt **klassificeringsproblem** (*falsk positiv*).\n\n> Derfor kan maskiner ikke være sexistiske eller racistiske. Men der eksisterer (stadig) systematisk sexisme og racisme og disse forhold vil være afspejlet i den data vi træner modeller på. \n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n:::{.incremental}\n* *Datatype og -omfang*: Ægte data eller ideel data (the unicorn)? \n* *Definerede opgaver*: Maskiner besejrer os, fordi vi beder dem om det. Det er ikke en skjult *motivation* (Luda, Tay: \"thinking about you\"). \n* *Tabsfunktionen*: målet vi bruger til at bestemme, hvor langt maskinen er fra at løse problemet. En grundlæggende menneskebestemt komponent. \n:::\n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n> *\"Du har en befolkning, hvor 0,5 procent får en alvorlig sygdom, og træner en model til at identificere dem. Modellen opnår hurtigt en høj træfsikkerhed på 99,5 procent, men er ikke i stand til at identificere en eneste af de syge. Hvad er der sket?\"* (fra Inga Strümke)\n\n<span class=\"timer\" data-time=\"120\"></span>\n\n## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel\n\nHver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.\n\n:::{.incremental}\n* Udviklere bestemmer hvornår en model er færdig. \n    * alt fra simpel ML og *deep learning* handler grundlæggende \"bare\" om kontinuerlig tilpasning af parametre indtil fejlen er så lille som muligt. \n    * **Universel approximation**: tilnærmelse af den sande funktion og fordeling.  \n    * Det meste af fremgangen indenfor AI er takket være **brute force** og *enorme mængde data*, snarer end vi har formået at putte mere \"intellegens\" ind i modeller. \n:::\n\n## Skyggesiderne af det digital samfund {background-image=\"resources/bad-ai.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.2\"}\n\n<br>\n\n**De klassiske:**\n\n- Datasikkerhed\n- Privatliv \n- Rettigheder (og ejerskab)\n\n**De \"nye\":**\n\n- Diskrimination og gennemsigtighed\n- (Klima)\n- (Ubegrundet/overdreven optimisme?)\n\n## (Data)sikkerhed {background-image=\"resources/eu.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n:::{.incremental}\n* **GDPR**: for lidt og for meget?\n    * Forskningsarbejde, der ikke må anvendes i praksis. \n    * Production af personfølsom data ([2018 studie på Facebook data](https://doi.org/10.1073/pnas.1802331115))\n    * Antag at de store techvirksomheder ved *midst* lige så meget om dig, som du selv gør!\n    * Giver mere regulering mening, når vi ikke ved hvad der bliver muligt i morgen?\n::: \n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Privatliv (1) {background-image=\"resources/privat.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n:::{.incremental}\n- Stort set alt hvad vi gør med digitale værktøjer (*computer, telefon, tv, SoMe, kort, kreditkort, ...*) **generer data**. \n  - I praksis er denne data ikke længere anonym. Når der er nok data, er det \"nemt\" at identificere personer. \n  - **The privacy paradox**. \n  - Det meste data er ikke *for* os, det er *om* os. \n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Privatliv (2) \n\n![](resources/peppespizza.jpeg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- **Anonymous Video Analytics**: Køn, Aldersgruppe, Attention time, Smile.\n- Tesla's overvågning af gadebilledet. Hvorfor er det mere acceptabelt? \n:::\n\n## Privatliv (3)\n\n:::{.incremental}\n- **Federated learning**: Google opfandt en måde at trænie modeller på vores mobiler, uden hjemsendelse af persondata; kun parametre. \n- **Formålsglidning**: bedste eksempel er NSA \n- Techgiganterne der ved meget om os er primært Amerikanske; resten er primært Kinesiske.\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Rettigheder og ejerskab {background-image=\"resources/antiai.png\" background-size=\"100%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.3\"}\n\n:::{.incremental}\n- Hvad ejer vi egentlig, når vi først har lagt det på nettet?\n- OpenAI 4. november 2022: *you own the generations you create with DALL-E* ([pkt. 5](https://help.openai.com/en/articles/6704941-dall-e-api-faq))\n  - **AI *er* kreative i en snæver defination af begrebet**. Men modeller er trænet på \"dit\" arbejde. \n- Vi kan ikke lave plagiat kontrol på en AI model, men ...    \n  - **Bør vi vandmærke AI modeller?**   \n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Rettigheder {background-image=\"resources/crime.png\" background-size=\"50%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.1\"}\n\n**Correctional Offender Management Profiling for Alternative Sanctions** ([COMPAS](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing))\n\n> *It assesses not just risk but also nearly two dozen so-called “criminogenic needs” that relate to the major theories of criminality, including “criminal personality,” “social isolation,” “substance abuse” and “residence/stability.” Defendants are ranked low, medium or high risk in each category.*\n\n:::{.incremental}\n::: {style=\"font-size: 0.9em;\"}\n- AI modeller er (typisk) udvikling af folk, der ikke er eksperter i **substansfeltet**. De er eksperter i AI og ML. \n- Neurale netværk er for kompliceret til at vi i dag, som mennesker kan se, hvad det er maskinen \"ser\". \n  - **Subsymbolsk viden**: Dataen mister sin betydning for mennesker.\n    - **Grænsetilfælde**: Det lange hale problem.  \n    - En ting er at et system virker, men hvis vi ikke ved *hvorfor* det virker, bør vi så tage det i brug .\n:::\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Diskrimination og gennemsigtighed (1)\n\n![](resources/pic-discrimination.jpg){fig-align=\"center\" width=50%}\n\n:::{.incremental}\n- Det er mennesker, der har adgang til hvilke kategorier en model har adgang til. (Sandsynligvis har afro- og/eller amerikaner, ikke været tilgængelig).\n:::\n\n## Diskrimination og gennemsigtighed (2) {background-image=\"resources/dis.png\" background-size=\"70%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.15\"}\n\n[Amazon Scraps Secret AI Recruiting Engine that Showed Biases Against Women](https://www.ml.cmu.edu/news/news-archive/2016-2020/2018/october/amazon-scraps-secret-artificial-intelligence-recruiting-engine-that-showed-biases-against-women.html)\n\n:::{.incremental}\n  - Endte som en *mande-detector*: Vi henter data fra en verden hvor hvide mænd har haft en priviligeret position. \n  - Er modellen sexistisk, hvis den kun har \"kendt\" en (data)verden, hvor strukturel sexisme eksisterer?\n  - Data kan ikke have bias. Data *er* bare. \n  - **Gennemsigtighed eller regulering?**\n:::\n\n<span class=\"timer\" data-time=\"300\"></span>\n\n## Diskrimination og gennemsigtighed (3) {background-image=\"resources/kant.jpg\" background-size=\"100%\" background-position=\"center\" background-repeat=\"no-repeat\" background-opacity=\"0.3\"}\n\n*Scrolling, autonomi og selvforstærkende mekanismer.*\n\n:::{.incremental}\n- Danner vi ønsker, eller bliver vi nudget til bestemte ønsker? \n- **Anbefalingssystemer**: er det tilpasning eller manipulation?\n- Deep fakes (billede og lyd). Google vi ikke frigive **AudioLM**.\n    * Lyd og billede kan ikke skelnes fra originaler. \n::: \n\n## Hvad er vi villige til at acceptere i et digitalt samfund? \n\n:::{.incremental}\n\n1. Har vi tænkt over hvad vi vil og ikke vil være med til?\n\n2. Opvejet fordele og ulemper ...\n    * Kan vi overhovedet tage stilling til disse spørgsmål på forhånd eller er vi nødt til at diskutere det løbende?\n\n3. Hvem beslutter hvad vi vil og ikke vil? Og hvad er deres motivation for at beslutte som de gør?\n    * ...Befolkningens ve og vel?   \n    * ...Personlig fortjeneste?    \n    * ...Magt?    \n\n4. Hvad er alternativet?\n    * Kan vi sige fra, hvad ville der ske og hvordan gør vi?    \n\n:::\n\nDet vi kan sige er, at vi altid vil være på bagkant af teknologien. Vi skal derfor kunne forholde os kritisk til teknologi med kort varsel-\n\nI den ideelle verden:\n\n:::{.incremental}\n\n1. ... er der gennemsigtighed omkring beslutningsprocesser og aktørers roller\n2. ... er der plads til demokratisk proces\n3. ... er det bl.a. jer og jeres fagfæller, mere end nogen anden der skal være med til at finde svarene ...\n\n:::\n\n# Grupperdannelse og præsentation af mini-projekter"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":true,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","highlight-style":"github","include-after-body":["resources/timer.html"],"embed-resources":true,"include-in-header":[{"text":"<link href=\"https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap\" rel=\"stylesheet\">\n<style>\n.reveal {\n  font-family: \"Libre Baskerville\", serif !important;\n}\n.reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {\n  font-family: \"Libre Baskerville\", serif !important;\n}\n</style>\n"}],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.7.32","auto-stretch":true,"theme":"default","transition":"slide","backgroundTransition":"fade","scrollable":true,"controls":true,"navigationMode":"linear","title":"(D)en digital verden – utopi eller dystopi?","subtitle":"","author":"Jeppe Fjeldgaard Qvist","date":"today","slideNumber":"c","showSlideNumber":"print","smaller":true}}},"projectFormats":["revealjs"]}