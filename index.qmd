---
title: "(D)en digital verden – utopi eller dystopi?"
subtitle: ""
author: "Jeppe Fjeldgaard Qvist"
date: today
format: 
  revealjs:
    include-after-body: "resources/timer.html"
    navigation-mode: linear
    slide-number: c
    show-slide-number: print
    embed-resources: true
    self-contained-math: true
    smaller: true
    scrollable: true
    theme: default
    include-in-header: 
      - text: |
          <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
          <style>
          .reveal {
            font-family: "Libre Baskerville", serif !important;
          }
          .reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
            font-family: "Libre Baskerville", serif !important;
          }
          </style>
---

## Dagens program


## Det digitale samfund 

> Det, at flere og flere aspekter af vores liv og hverdag digitaliseres, stiller ikke kun store krav til de underliggende systemer, men rejser også mange fundamentale spørgsmål; såvel tekniske som etiske.

---

![](resources/pic-accident.jpg){fig-align="center" width=50%}

---

![](resources/pic-accident.jpg){fig-align="center" width=50%}

Et **klassificeringsproblem** (*falsk positiv*).

---

![](resources/pic-accident.jpg){fig-align="center" width=50%}

Et **klassificeringsproblem** (*falsk positiv*).

> Hvem bærer skylden: Maskinen eller Rafaela, der var "andenpilot"?

---

![](resources/pic-accident.jpg){fig-align="center" width=50%}

Et **klassificeringsproblem** (*falsk positiv*).

> Al data, der ligger til grund for maskines klassificerings-evner bygger på data som mennesker har haft ansvaret for. Maskiner forholder sig ikke til andet end tal. 

---

![](resources/pic-accident.jpg){fig-align="center" width=50%}

Et **klassificeringsproblem** (*falsk positiv*).

> Derfor kan maskiner ikke være sexistiske eller racistiske. Men der eksisterer (stadig) systematisk sexisme og racisme og disse forhold vil være afspejlet i den data vi træner modeller på. 

## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel

Hver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.

:::{.incremental}
* *Datatype og -omfang*: Ægte data eller ideel data (the unicorn)? 
* *Definerede opgaver*: Maskiner besejrer os, fordi vi beder dem om det. Det er ikke en skjult *motivation* (Luda, Tay: "thinking about you"). 
* *Tabsfunktionen*: målet vi bruger til at bestemme, hvor langt maskinen er fra at løse problemet. En grundlæggende menneskebestemt komponent. 
:::

## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel

Hver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.

> *"Du har en befolkning, hvor 0,5 procent får en alvorlig sygdom, og træner en model til at identificere dem. Modellen opnår hurtigt en høj træfsikkerhed på 99,5 procent, men er ikke i stand til at identificere en eneste af de syge. Hvad er der sket?"* (fra Inga Strümke)

<span class="timer" data-time="120"></span>

## *Dataindsamling* og *tabsfunktionen*: den menneskelige vinkel

Hver gang AI bruges til at træffe en beslutning (alt fra **klassifikation** til et **skak-træk**) ligger der menneskebestemte afvejninger bag.

:::{.incremental}
* Udviklere bestemmer hvornår en model er færdig. 
    * alt fra simpel ML og *deep learning* handler grundlæggende "bare" om kontinuerlig tilpasning af parametre indtil fejlen er så lille som muligt. 
    * **Universel approximation**: tilnærmelse af den sande funktion og fordeling.  
    * Det meste af fremgangen indenfor AI er takket være **brute force** og *enorme mængde data*, snarer end vi har formået at putte mere "intellegens" ind i modeller. 
:::

## Skyggesiderne af det digital samfund 

<br>

**De klassiske:**

- Datasikkerhed
- Privatliv 
- Rettigheder 

**De "nye":**

- Diskrimination og gennemsigtighed [*Rettigheder*]
- Klima
- (Ubegrundet/overdreven optimisme?)

## (Data)sikkerhed

:::{.incremental}
* **GDPR**: for lidt og for meget?
    * Forskningsarbejde, der ikke må anvendes i praksis. 
    * Production af personfølsom data ([2018 studie på Facebook data](https://doi.org/10.1073/pnas.1802331115))
    * Antag at de store techvirksomheder ved *midst* lige så meget om dig, som du selv gør!
    * Giver mere regulering mening, når vi ikke ved hvad der bliver muligt i morgen?
::: 

<span class="timer" data-time="300"></span>

## Privatliv 

:::{.incremental}
- Stort set alt hvad vi gør med digitale værktøjer (*computer, telefon, tv, SoMe, kort, kreditkort, ...*) **generer data**. 
  - I praksis er denne data ikke længere anonym. Når der er nok data, er det "nemt" at identificere personer. 
  - **The privacy paradox**. 
  - Det meste data er ikke *for* os, det er *om* os. 
:::

<span class="timer" data-time="300"></span>
